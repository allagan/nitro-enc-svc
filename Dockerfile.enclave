# Dockerfile.enclave
#
# Builds the nitro-enc-svc OCI image used as input to `nitro-cli build-enclave`.
# This image is NOT deployed to EKS or pushed to ECR — it is converted to an EIF file.
#
# All enclave configuration is baked in via ARG → ENV so that Config::from_env()
# can read it at enclave startup. nitro-cli run-enclave cannot inject env vars from
# the host into the enclave process.
#
# Required build args (must be supplied via --build-arg):
#   SECRET_ARN, KMS_KEY_ID, S3_BUCKET, VSOCK_PROXY_CID, OTEL_EXPORTER_OTLP_ENDPOINT
#
# Usage:
#   docker build -f Dockerfile.enclave \
#     --build-arg SECRET_ARN=arn:aws:... \
#     --build-arg KMS_KEY_ID=arn:aws:... \
#     --build-arg S3_BUCKET=my-bucket \
#     --build-arg VSOCK_PROXY_CID=3 \
#     --build-arg OTEL_EXPORTER_OTLP_ENDPOINT=http://127.0.0.1:4317 \
#     -t nitro-enc-svc-enclave:local .
#
#   nitro-cli build-enclave \
#     --docker-uri nitro-enc-svc-enclave:local \
#     --output-file nitro-enc-svc.eif

# ---------------------------------------------------------------------------
# Stage 1: Rust builder
# ---------------------------------------------------------------------------
FROM public.ecr.aws/amazonlinux/amazonlinux:2023 AS builder

# Install C build dependencies required by aws-lc-sys (transitive via AWS SDK crates).
RUN dnf install -y \
        gcc \
        gcc-c++ \
        cmake \
        make \
        openssl-devel \
        pkg-config \
        git \
        tar \
        gzip \
    && dnf clean all

# Install Rust via rustup with a minimal stable toolchain.
ENV RUSTUP_HOME=/usr/local/rustup \
    CARGO_HOME=/usr/local/cargo \
    PATH=/usr/local/cargo/bin:$PATH

RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | \
    sh -s -- -y --no-modify-path --profile minimal --default-toolchain stable \
    && rustup component add rustfmt clippy

WORKDIR /build

# ---------------------------------------------------------------------------
# Dependency caching layer
# Copy only manifest files and stub out source trees so `cargo fetch` can
# download all crates without needing the real source.  When only source
# files change on a rebuild, this layer is served from Docker cache.
# ---------------------------------------------------------------------------
COPY Cargo.toml Cargo.lock ./
COPY crates/common/Cargo.toml   crates/common/Cargo.toml
COPY crates/enclave/Cargo.toml  crates/enclave/Cargo.toml
COPY crates/vsock-proxy/Cargo.toml crates/vsock-proxy/Cargo.toml

RUN mkdir -p \
        crates/common/src \
        crates/enclave/src \
        crates/vsock-proxy/src \
    && echo 'pub fn stub() {}' > crates/common/src/lib.rs \
    && echo 'fn main() {}' > crates/enclave/src/main.rs \
    && echo 'fn main() {}' > crates/vsock-proxy/src/main.rs \
    && cargo fetch --locked

# ---------------------------------------------------------------------------
# Full source build — only this layer reruns on source changes.
# ---------------------------------------------------------------------------
COPY crates/ crates/

RUN cargo build --release --locked -p enclave

# ---------------------------------------------------------------------------
# Stage 2: Minimal runtime image (the enclave rootfs)
# ---------------------------------------------------------------------------
FROM public.ecr.aws/amazonlinux/amazonlinux:2023 AS runtime

# Install runtime dependencies:
#   ca-certificates — TLS verification for AWS API calls (end-to-end via vsock)
#   openssl         — generates the dev self-signed TLS cert (see below)
#   socat           — TCP-to-vsock bridge for IMDS credential proxy
#
# DEV NOTE: A self-signed TLS cert is generated here so the enclave can start
# without ACM for Nitro Enclaves.  For production, remove the openssl install
# and cert-generation block; the ACM for Nitro Enclaves agent delivers the
# real cert+key to /run/acm/ over vsock before the process reads them.
RUN dnf install -y ca-certificates openssl socat \
    && dnf clean all \
    && mkdir -p /run/acm \
    && openssl req -x509 -newkey rsa:2048 -sha256 \
         -keyout /run/acm/tls.key \
         -out /run/acm/tls.crt \
         -days 3650 -nodes \
         -subj '/CN=nitro-enc-svc.local' \
    && chmod 400 /run/acm/tls.key /run/acm/tls.crt

COPY --from=builder /build/target/release/enclave /usr/local/bin/enclave

# ---------------------------------------------------------------------------
# Entrypoint wrapper — starts the IMDS vsock bridge then execs the enclave.
# The bridge forwards IMDS HTTP traffic through vsock to the parent EC2,
# where vsock-proxy relays it to the real IMDS endpoint (169.254.169.254:80).
# The enclave binary reads AWS_EC2_METADATA_SERVICE_ENDPOINT to find the
# bridge address instead of trying the link-local IMDS address directly.
# ---------------------------------------------------------------------------
COPY scripts/enclave-entrypoint.sh /usr/local/bin/enclave-entrypoint.sh
RUN chmod +x /usr/local/bin/enclave-entrypoint.sh

# ---------------------------------------------------------------------------
# Configuration — baked into the EIF as ENV instructions.
#
# REQUIRED: CodeBuild (or local docker build) must supply these via --build-arg.
# If any required var is empty, Config::from_env() will exit at enclave startup
# with a clear error message visible in `nitro-cli console` output.
# ---------------------------------------------------------------------------
ARG SECRET_ARN
ARG KMS_KEY_ID
ARG S3_BUCKET
ARG VSOCK_PROXY_CID
ARG OTEL_EXPORTER_OTLP_ENDPOINT

ENV SECRET_ARN=${SECRET_ARN} \
    KMS_KEY_ID=${KMS_KEY_ID} \
    S3_BUCKET=${S3_BUCKET} \
    VSOCK_PROXY_CID=${VSOCK_PROXY_CID} \
    OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}

# ---------------------------------------------------------------------------
# OPTIONAL: override defaults from config.rs if needed per environment.
# ---------------------------------------------------------------------------
ARG S3_PREFIX=schemas/
ARG SCHEMA_HEADER_NAME=X-Schema-Name
ARG DEK_ROTATION_INTERVAL_SECS=3600
ARG SCHEMA_REFRESH_INTERVAL_SECS=300
ARG VSOCK_PROXY_PORT=8000
ARG TLS_PORT=443
# Paths to the TLS cert and key.  In dev, these are the self-signed files
# generated above.  In production, override to the paths where the ACM for
# Nitro Enclaves agent deposits the real certificate and private key.
ARG TLS_CERT_PATH=/run/acm/tls.crt
ARG TLS_KEY_PATH=/run/acm/tls.key
ARG LOG_LEVEL=info

# AWS region baked in so the SDK doesn't query IMDS for region detection.
ARG AWS_REGION=us-east-2
ARG AWS_DEFAULT_REGION=us-east-2

# IMDS redirect: socat bridges TCP 127.0.0.1:8004 → vsock(VSOCK_PROXY_CID, 8004),
# and vsock-proxy on the parent forwards vsock:8004 to 169.254.169.254:80.
ARG AWS_EC2_METADATA_SERVICE_ENDPOINT=http://127.0.0.1:8004

ENV S3_PREFIX=${S3_PREFIX} \
    SCHEMA_HEADER_NAME=${SCHEMA_HEADER_NAME} \
    DEK_ROTATION_INTERVAL_SECS=${DEK_ROTATION_INTERVAL_SECS} \
    SCHEMA_REFRESH_INTERVAL_SECS=${SCHEMA_REFRESH_INTERVAL_SECS} \
    VSOCK_PROXY_PORT=${VSOCK_PROXY_PORT} \
    TLS_PORT=${TLS_PORT} \
    TLS_CERT_PATH=${TLS_CERT_PATH} \
    TLS_KEY_PATH=${TLS_KEY_PATH} \
    LOG_LEVEL=${LOG_LEVEL} \
    AWS_REGION=${AWS_REGION} \
    AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} \
    AWS_EC2_METADATA_SERVICE_ENDPOINT=${AWS_EC2_METADATA_SERVICE_ENDPOINT}

# Run as root inside the enclave VM (isolated environment — no host sharing).
# The IMDS bridge needs net stack access; the cert files are root-owned.

# The Nitro Enclave kernel boots the container ENTRYPOINT as PID 1.
ENTRYPOINT ["/usr/local/bin/enclave-entrypoint.sh"]
